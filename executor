# Executor Adapter Scalarm
#!/usr/bin/env ruby
# encoding: UTF-8
require 'json'

class NewWorkFlow
    @base_Dir = String.new

  def initialize(dir)
    @submit_dir = dir
    @workflow_label = "genomeOutput"
  end

################################################## Start the workflow to run on Pegasus #############################################
  def start
  	##For re-run of workflow on Failure
    dir = ""
	  if File.exist?('location.txt') 
	      File.open("location.txt") do |file|
	          file.each do |line|
	            dir = dir << line
	          end
	      end
	  end

		if(dir != "")
		@status = update_status
		    if(@status == "Success")
		    else 
		    	puts "RUN"
		    	`pegasus-run #{dir}`
		    end
    ## END
    ## Run the workflow: Create new Scalarm Manager
		else
	    # generate-dax  <WORK_DIR>  <LANEFILE>  <BINSIZE> : Format for genomeWorkflow (will vary for respective Workflows)
		cmd =["cd #{@submit_dir}","./generate-dax work /data/scratch/rafsilva/workflow/genome/lanes/test_4000 100"].join("; ")  
	    %x[#{cmd}]
	    cmd =["cd #{@submit_dir}","./plan-dax work execution"].join("; ")
	    @base_Dir = %x[#{cmd}]
		end
    ##END
  end
############################################################### END ###############################################################


############################# Reading the base directory formed on-fly: workflow starts successfully ##############################
  def getBaseDir
    analyzer_Dir = ""
    lookFor = "/data/scratch/rafsilva/workflow/genome/work/rafsilva/pegasus/genome-dax/"
    @base_Dir.each_line do |line|
    if line.include? lookFor
      analyzer_Dir = line
      break if analyzer_Dir !=  ""
    end
    end
    a_Dir = analyzer_Dir.split(lookFor)
    lookFor << a_Dir[1]
    if not File.exist?('location.txt') # Store the location in a file to be read for Progress-Monitor adapter
	  open('location.txt', 'w') { |f|
	  f.puts lookFor
	}
	end
    return lookFor
  end
############################################################### END ###############################################################


###################################################### Get Workflow current state #################################################
def update_status
    lookFor = self.getBaseDir
    pegasus_status = `pegasus-status -l #{lookFor}`
    @status = parse_pegasus_status(pegasus_status)
    return @status
end

def running? # Syncing Scalarm with Pegasus workflow execution
    @status = update_status
    if(@status == "Running")
    	return true
    else 
    	return false
    end
end

def failed? # Check for status Failure
     @status = update_status
    if(@status == "Failure")
    	return true
    else 
    	return false
    end
end
   
   ## Function to Parse the Status out and get the value of the current workflow status state
def parse_pegasus_status(status_output)
    parse_summary_mode = false
    state = "Running"
    status_output.split("\n").each do |line|
      if line.start_with? "UNRDY"
        parse_summary_mode = true
      elsif parse_summary_mode
        summary = line.split
        state = summary[8]
        parse_summary_mode = false
      end
    end
return state
end ##END

############################################################### END ###############################################################

########################################################## Pegasus-Analyzer #######################################################
def analyzer
lookFor = self.getBaseDir # Pegasus cmd: Run on the newly created directory on-fly (Gets the directory location)
return `pegasus-analyzer -d #{lookFor}`# Pegasus cmd: command used to gather information of the jobs at hand (Can also hold information to identify the jobs that failed and reason for failure)
end
############################################################### END ###############################################################


########################################################## Pegasus-Statistics #####################################################
   ## Function to Parse Pegasus Statistics output
   ## Parsing Result Format:
		# Type           Succeeded Failed  Incomplete  Total     Retries   Total+Retries
		# Tasks          5         0       0           5         0         5            
		# Jobs           15        0       0           15        0         15           
		# Sub-Workflows  0         0       0           0         0         0            
		# Workflow wall time                                       : 2 mins, 6 secs
		# Workflow cumulative job wall time                        : 38 secs
		# Cumulative job wall time as seen from submit side        : 42 secs
		# Workflow cumulative job badput wall time                 : 
		# Cumulative job badput wall time as seen from submit side : 
def parse_pegasus_job_statistics(content)
    parsed_statistics_output = {}
    check_ForI = {"Tasks" => "R1","Jobs" => "R2","Sub-Workflows" => "R3"} # HashSet could be used
    check_ForII = {"Workflowwalltime" => "Wall time: ", "Cumulativejobwalltime" => "Cumulative wall time: ", "Cumulativejobwalltimeasseenfromsubmitside" => "Cumulative Wall Time - submit code:", "Cumulativejobbadputwalltime" => "Cumulative badput wall time: ", "Cumulativejobbadputwalltimeasseenfromsubmitside" => "Cummulative badput wall Time - submit code: "}
    content.split("\n").each do |line|
      if line.include? "Type"
      	parsed_statistics_output["Summary"] = line
      elsif(!line[Regexp.union(check_ForI.keys)].nil?) 
      	key = line[Regexp.union(check_ForI.keys)]
      	parsed_statistics_output[key] = line
      elsif (line.include? ":")
      	s = line.split(":")
      	key = s[0].gsub(/\s+/, '')
      	if(check_ForII.has_key? key)
      		if(s[1].nil?)
      		s[1] = " "
      		end
      		parsed_statistics_output[check_ForII[key]] = check_ForII[key]<<s[1]
      	end
      end
    end
    #Print in a readable format
    parsed_statistics_output.each do |key, value|
    puts value
    end
end ##END


# Statistics: pegasus-statistics
def jobs_statistics
    lookFor = self.getBaseDir
      cmd = "pegasus-statistics -s all #{lookFor}" # Pegasus cmd: command used to gather statistics about the runtime of the workflow and its jobs
      puts "Command: #{cmd}"
      output = %x[#{cmd}] # Ruby syntax: command execution
      parse_pegasus_job_statistics(output) # Function help: Display the necessary result in the output window Scalarm
      return output
end
############################################################### END ###############################################################




########################################################## Workflow Run Results ####################################################
def full_results(flag)
    if(flag==0) #Flag==0 implies that the Workflow run successfully without errors
  	outputs = {}
    # Put the content of analyzer and Statistics in the output.json file
    outputs["Summary"] = self.analyzer # Pegasus Analyzer Output
    outputs["Statistics"] = self.jobs_statistics # Pegasus Statistics Output
    return outputs # json object: Return Json object on workflow success
  else
    a = self.analyzer
    return a # Reason for Failure: output json file requires string to as output for reason
  end
end
############################################################### END ###############################################################

end # End Class NewWorkFlow


#== Main Script ==##
def main
  dir = "/data/scratch/rafsilva/workflow/genome" # Non-generic: Specify the directory respectively

  workflow = NewWorkFlow.new(dir)
  workflow.start # Start the new workflow run on Pegasus

  sleep 30

  #  Scalarm Progress Bar: shows Green till the workflow in State: Running ()
 while (workflow.running?)
    sleep 10
  end

  sleep 30

  if workflow.failed?
  	# Result: The json output comprises of the Pegasus analyzer output(with reason for Failure)
  	IO.write 'output.json', { status: 'error', reason: workflow.full_results(1) }.to_json
  else
  	#Fetch the output file for Scalarm
    %x[mkdir #{workflow.workflow_label}]
    %x[tar czvf output.tar.gz --directory=/data/scratch/rafsilva/workflow/genome outputs/]
    sleep 30
    # Result: The json output comprises of the Pegasus analyzer output and Pegasus Statistics Output
    IO.write 'output.json', { status: 'ok', results: workflow.full_results(0) }.to_json
  end
end

main
