#!/usr/bin/env ruby
# encoding: UTF-8
require 'json'

class NewWorkFlow
    @base_Dir = String.new

  def initialize(dir)
    @submit_dir = dir
    @workflow_label = "genomeOutput"
  end

################################################## Start the workflow to run on Pegasus #############################################
  def start
  	##For re-run of workflow on Failure
    dir = ""
	  if File.exist?('location.txt') 
	      File.open("location.txt") do |file|
	          file.each do |line|
	            dir = dir << line
	          end
	      end
	  end

		if(dir != "")
		@status = update_status
		    if(@status == "Success")
		    else 
		    	puts "RUN"
		    	`pegasus-run #{dir}`
		    end
    ## END
    ## Run the workflow: Create new Scalarm Manager
		else
	    # generate-dax  <WORK_DIR>  <LANEFILE>  <BINSIZE> : Format for genomeWorkflow (will vary for respective Workflows)
		cmd =["cd #{@submit_dir}","./generate-dax work /data/scratch/rafsilva/workflow/genome/lanes/test_4000 100"].join("; ")  
	    %x[#{cmd}]
	    cmd =["cd #{@submit_dir}","./plan-dax work execution"].join("; ")
	    @base_Dir = %x[#{cmd}]
		end
    ##END
  end
############################################################### END ###############################################################


############################# Reading the base directory formed on-fly: workflow starts successfully ##############################
  def getBaseDir
    analyzer_Dir = ""
    lookFor = "/data/scratch/rafsilva/workflow/genome/work/rafsilva/pegasus/genome-dax/"
    @base_Dir.each_line do |line|
    if line.include? lookFor
      analyzer_Dir = line
      break if analyzer_Dir !=  ""
    end
    end
    a_Dir = analyzer_Dir.split(lookFor)
    lookFor << a_Dir[1]
    if not File.exist?('location.txt') # Store the location in a file to be read for Progress-Monitor adapter
	  open('location.txt', 'w') { |f|
	  f.puts lookFor
	}
	end
    return lookFor
  end
############################################################### END ###############################################################


###################################################### Get Workflow current state #################################################
def update_status
    lookFor = self.getBaseDir
    pegasus_status = `pegasus-status -l #{lookFor}`
    @status = parse_pegasus_status(pegasus_status)
    return @status
end

def running? # Syncing Scalarm with Pegasus workflow execution
    @status = update_status
    if(@status == "Running")
    	return true
    else 
    	return false
    end
end

def failed? # Check for status Failure
     @status = update_status
    if(@status == "Failure")
    	return true
    else 
    	return false
    end
end
   
   ## Function to Parse the Status out and get the value of the current workflow status state
def parse_pegasus_status(status_output)
    parse_summary_mode = false
    state = "Running"
    status_output.split("\n").each do |line|
      if line.start_with? "UNRDY"
        parse_summary_mode = true
      elsif parse_summary_mode
        summary = line.split
        state = summary[8]
        parse_summary_mode = false
      end
    end
return state
end ##END

############################################################### END ###############################################################

########################################################## Pegasus-Analyzer #######################################################
def analyzer
lookFor = self.getBaseDir
return `pegasus-analyzer -d #{lookFor}`
end
############################################################### END ###############################################################


########################################################## Pegasus-Statistics #####################################################
   ## Function to Parse Statistics out and get the value of the current workflow status state
def parse_pegasus_job_statistics(content)
    parsed_statistics_output = {}
    check_ForI = {"Tasks" => "R1","Jobs" => "R2","Sub-Workflows" => "R3"} # HashSet could be used
    check_ForII = {"Workflow wall time" => "Wall time: ", "Workflow cumulative job wall time" => "Cummulative wall Time: ", "Cumulative job wall time as seen from submit side" => "Cummulative Wall Time - submit code:", "Workflow cumulative job badput wall time" => "Cumulative badput wall time: ", "Cumulative job badput wall time as seen from submit side" => "Cummulative badput wall Time - submit code: "}
    content.split("\n").each do |line|
      if line.include? "Type"
      	parsed_statistics_output["Summary"] = line
      elsif(!line[Regexp.union(check_ForI.keys)].nil?)
      	key = line[Regexp.union(check_ForI.keys)]
      	parsed_statistics_output[key] = line
      elsif (!line[Regexp.union(check_ForII.keys)].nil?)
      	s = line.split(":")
      	key = line[Regexp.union(check_ForII.keys)]
      	parsed_statistics_output[check_ForII[key]] = s[1]
      end
    end
    # puts parsed_output
    puts parsed_statistics_output
end ##END


# Statistics: pegasus-statistics
def jobs_statistics
    lookFor = self.getBaseDir
      cmd = "pegasus-statistics -s all #{lookFor}"
      puts "Command: #{cmd}"
      output = %x[#{cmd}]
      parse_pegasus_job_statistics(output)
      return output
end
############################################################### END ###############################################################




########################################################## Workflow Run Results ####################################################
def full_results(flag)
    if(flag==0) 
  	outputs = {}
    # Put the content of analyzer and Statistics in the output.json file
    outputs["Summary"] = self.analyzer
    outputs["Statistics"] = self.jobs_statistics
    return outputs
  else
    a = self.analyzer
    s = self.jobs_statistics
    puts a<<s
    return a<<s
  end
end
############################################################### END ###############################################################

end # End Class NewWorkFlow


#== Main Script ==##
def main
  dir = "/data/scratch/rafsilva/workflow/genome"

  workflow = NewWorkFlow.new(dir)
  workflow.start # Start the new workflow run on Pegasus

  sleep 30

  #  Scalarm Progress Bar: shows Green till the workflow in State: Running
 while (workflow.running?)
    sleep 10
  end

  sleep 30

    # Remove the on-fly create file: Since being used for Re-run have not removed the file created on-fly
    # File.delete("location.txt") if File.exist?("location.txt")

  if workflow.failed?
  	IO.write 'output.json', { status: 'error', reason: workflow.full_results(1) }.to_json
  else
    %x[mkdir #{workflow.workflow_label}]
    %x[tar czvf output.tar.gz --directory=/data/scratch/rafsilva/workflow/genome outputs/]
    sleep 30

    IO.write 'output.json', { status: 'ok', results: workflow.full_results(0) }.to_json
  end
end

main
